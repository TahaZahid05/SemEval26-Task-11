{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d51f5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.11-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (27 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-3.0.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Requirement already satisfied: tqdm in /home/taha/miniconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Collecting inflect\n",
      "  Using cached inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.12-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.10-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from spacy) (0.20.0)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.4.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/taha/miniconda3/lib/python3.13/site-packages (from spacy) (2.12.4)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/taha/miniconda3/lib/python3.13/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/taha/miniconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/taha/miniconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/taha/miniconda3/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/taha/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/taha/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/taha/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/taha/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading wrapt-2.1.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2026.1.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/taha/miniconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: more_itertools>=8.5.0 in /home/taha/miniconda3/lib/python3.13/site-packages (from inflect) (10.8.0)\n",
      "Collecting typeguard>=4.0.1 (from inflect)\n",
      "  Using cached typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/taha/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Downloading spacy-3.8.11-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m595.4 kB/s\u001b[0m  \u001b[33m0:00:55\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (254 kB)\n",
      "Downloading murmurhash-1.0.15-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (133 kB)\n",
      "Downloading preshed-3.0.12-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (835 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m835.9/835.9 kB\u001b[0m \u001b[31m575.9 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m[31m572.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m587.9 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.10-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m576.6 kB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\u001b[31m554.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m543.5 kB/s\u001b[0m  \u001b[33m0:00:20\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.4.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m551.1 kB/s\u001b[0m  \u001b[33m0:00:30\u001b[0m\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Downloading pandas-3.0.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m535.5 kB/s\u001b[0m  \u001b[33m0:00:20\u001b[0m\u001b[31m535.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Downloading regex-2026.1.15-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m580.9 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading wrapt-2.1.0-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Installing collected packages: wrapt, wasabi, typeguard, spacy-loggers, spacy-legacy, regex, numpy, murmurhash, MarkupSafe, joblib, cymem, cloudpathlib, catalogue, srsly, smart-open, preshed, pandas, nltk, jinja2, inflect, blis, confection, weasel, thinc, spacy\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [spacy]7m━\u001b[0m \u001b[32m24/25\u001b[0m [spacy][thinc]]thlib]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "generate-parameter-library-py 0.6.0 requires pyyaml, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 blis-1.3.3 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 inflect-7.5.0 jinja2-3.1.6 joblib-1.5.3 murmurhash-1.0.15 nltk-3.9.2 numpy-2.4.2 pandas-3.0.0 preshed-3.0.12 regex-2026.1.15 smart-open-7.5.0 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.2 thinc-8.3.10 typeguard-4.4.4 wasabi-1.1.3 weasel-0.4.3 wrapt-2.1.0\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/taha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/taha/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install spacy nltk pandas tqdm inflect\n",
    "!python -m spacy download en_core_web_sm\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82565ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c56e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the inflect engine (for English singular/plural detection)\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GERMAN_COMPLEX_PATTERNS = {\n",
    "    'premises': {\n",
    "        'all': [\n",
    "            {'tpl': 'Alle {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Alle {a_pl} gehören zur Klasse {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Ohne Ausnahme sind alle {a_pl} {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Jedes {a_sg} ist {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Jeder einzelne {a_sg} gehört zur Kategorie {b_sg}.', 'a_type': 'singular', 'b_type': 'singular'},\n",
    "            {'tpl': 'Alles, was {a_sg_art} ist, ist {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Wenn etwas {a_sg_art} ist, dann ist es auch {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Die Klasse der {a_pl} ist eine Teilmenge von {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Sämtliche {a_pl} werden als {b_pl} eingestuft.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es gibt kein {a_sg}, das nicht {b_sg_art} ist.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Wer {a_sg_art} ist, qualifiziert sich als {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Alle Vertreter von {a_pl} zählen zu {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Jedes {a_sg} ist notwendigerweise {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': '{a_pl} sind ausnahmslos {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Die Gesamtheit der {a_pl} fällt unter {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'}\n",
    "        ],\n",
    "        'some': [\n",
    "            {'tpl': 'Einige {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es gibt einige {a_pl}, die {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Mindestens ein {a_sg} ist {b_sg}.', 'a_type': 'singular', 'b_type': 'singular'},\n",
    "            {'tpl': 'In manchen Fällen ist {a_sg_art} {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Einige wenige {a_pl} sind tatsächlich {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Bestimmte {a_pl} weisen Merkmale von {b_pl} auf.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es existieren {a_pl}, die auch {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Ein Teil der {a_pl} gehört zu {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Man kann {a_pl} finden, die {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es kommt vor, dass {a_sg_art} {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Nicht alle, aber doch einige {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Gelegentlich ist ein {a_sg} auch {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Es gibt Instanzen von {a_pl}, die als {b_pl} gelten.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Eine gewisse Anzahl an {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Zumindest manche {a_pl} sind in {b_pl} enthalten.', 'a_type': 'plural', 'b_type': 'plural'}\n",
    "        ],\n",
    "        'no': [\n",
    "            {'tpl': 'Keine {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es gibt keine {a_pl}, die {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Kein {a_sg} kann als {b_sg_art} gelten.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Nichts, das {a_sg_art} ist, ist {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Überhaupt keine {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Niemals ist ein {a_sg} zugleich {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Die Mengen {a_pl} und {b_pl} sind disjunkt.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es ist ausgeschlossen, dass {a_sg_art} {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Keinerlei {a_pl} gehören zur Klasse {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Ein {a_sg} ist unter keinen Umständen {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Es existiert keine Überschneidung zwischen {a_pl} und {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Wenn etwas {a_sg_art} ist, kann es nicht {b_sg_art} sein.', 'a_type': 'singular_art', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'In der Gruppe der {a_pl} findet man kein einziges {b_sg}.', 'a_type': 'plural', 'b_type': 'singular'},\n",
    "            {'tpl': 'Es ist falsch, dass irgendein {a_sg} {b_sg_art} ist.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Absolut kein {a_sg} ist {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'}\n",
    "        ],\n",
    "        'some_not': [\n",
    "            {'tpl': 'Einige {a_pl} sind nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Nicht jedes {a_sg} ist {b_sg_art}.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Es gibt mindestens ein {a_sg}, das nicht {b_sg_art} ist.', 'a_type': 'singular', 'b_type': 'singular_art'},\n",
    "            {'tpl': 'Mindestens einige {a_pl} sind nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es gibt {a_pl}, die nicht {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Manche {a_pl} fallen nicht unter die Kategorie {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Ein Teil der {a_pl} ist von {b_pl} ausgeschlossen.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es ist nicht der Fall, dass alle {a_pl} {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Bestimmte {a_pl} sind keine {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Man findet {a_pl}, die nicht {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Es existieren Exemplare von {a_pl}, die keine {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Nicht alle Vertreter von {a_pl} sind {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'},\n",
    "            {'tpl': 'Einige {a_pl} besitzen die Eigenschaft {b_sg} nicht.', 'a_type': 'plural', 'b_type': 'singular'},\n",
    "            {'tpl': 'Es gibt Fälle, in denen ein {a_sg} kein {b_sg} ist.', 'a_type': 'singular', 'b_type': 'singular'},\n",
    "            {'tpl': 'Ein gewisser Anteil an {a_pl} ist nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural'}\n",
    "        ]\n",
    "    },\n",
    "    'conclusions': [\n",
    "        'Daher {conclusion}.',\n",
    "        'Folglich {conclusion}.',\n",
    "        'Somit {conclusion}.',\n",
    "        'Aus diesen Gründen {conclusion}.',\n",
    "        'Demnach {conclusion}.',\n",
    "        'Man kann daraus schließen, dass {conclusion}.',\n",
    "        'Infolgedessen {conclusion}.',\n",
    "        'Das bedeutet, dass {conclusion}.',\n",
    "        'Daraus ergibt sich: {conclusion}.',\n",
    "        'Zusammenfassend lässt sich sagen, dass {conclusion}.'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GERMAN_COMPLEX_PATTERNS_WITH_FOURTH_VAR = {\n",
    "    'premises': {\n",
    "        'all': [\n",
    "            {'tpl': 'Jedes {d_sg}, das {a_sg_art} ist, ist auch {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Wenn {d_sg_art} {a_sg_art} ist, dann muss es {b_sg_art} sein.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular_art'},\n",
    "            {'tpl': 'Alle {d_pl}, die {a_pl} sind, sind ebenfalls {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Ohne Ausnahme gelten die {d_pl}, die {a_pl} sind, als {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Jedes einzelne {d_sg} in {a_sg_art} ist {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Jeder {d_sg}, der als {a_sg_art} gilt, ist notwendigerweise {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Für jedes {d_sg}, das zugleich {a_sg_art} ist, gilt, dass es {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Alles aus {d_pl}, was {a_sg_art} ist, gehört auch zu {b_pl}.', 'a_type': 'singular_art', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Wenn ein {d_sg} {a_sg_art} ist, folgt daraus, dass es {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Die Gesamtheit der {d_pl} mit der Eigenschaft {a_pl} ist in {b_pl} enthalten.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Innerhalb von {d_pl} sind alle {a_pl} zugleich {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Wer in {d_pl} {a_sg_art} ist, ist immer auch {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'plural'},\n",
    "            {'tpl': 'Kein {d_sg} ist {a_sg_art}, ohne auch {b_sg_art} zu sein.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Jedes Exemplar von {d_pl}, das unter {a_pl} fällt, ist {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es ist sicher, dass jedes {d_sg}, das {a_sg} ist, auch {b_sg} ist.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'}\n",
    "        ],\n",
    "        'some': [\n",
    "            {'tpl': 'Es existiert mindestens ein {d_sg}, das sowohl {a_sg_art} als auch {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Zumindest ein {d_sg}, das {a_sg_art} ist, ist {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Einige {d_pl} sind sowohl {a_pl} als auch {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Man findet {d_pl}, die {a_pl} und zugleich {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Mindestens eines der {d_pl} ist {a_pl} und {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es gibt Fälle in {d_pl}, in denen {a_sg_art} auch {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'plural'},\n",
    "            {'tpl': 'Bestimmte {d_pl} weisen sowohl {a_pl} als auch {b_pl} Merkmale auf.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es existieren Exemplare von {d_sg}, die {a_sg} und {b_sg} vereinen.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Unter den {d_pl} gibt es solche, die {a_pl} und {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Einige {d_pl} fallen unter die Kategorien {a_pl} und {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Man stößt auf {d_sg}, die gleichzeitig {a_sg_art} und {b_sg_art} sind.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Nicht selten ist ein {d_sg} sowohl {a_sg} als auch {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'In der Gruppe {d_pl} finden sich {a_pl}, die {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Teilweise sind {d_pl} sowohl {a_pl} als auch {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es kommen {d_pl} vor, die Merkmale von {a_pl} und {b_pl} zeigen.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'}\n",
    "        ],\n",
    "        'no': [\n",
    "            {'tpl': 'Keines der {d_pl}, die {a_pl} sind, ist {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Nichts ist gleichzeitig {d_sg_art}, {a_sg_art} und {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular_art'},\n",
    "            {'tpl': 'Überhaupt keine {d_pl} sind {b_pl}, wenn sie {a_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es gibt keine {d_pl}, die sowohl {a_pl} als auch {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Nicht ein {d_sg} existiert, das {a_sg} und {b_sg} zugleich wäre.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Es ist unmöglich, dass ein {d_sg} zugleich {a_sg_art} und {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Kein Vertreter von {d_pl} kann sowohl {a_pl} als auch {b_pl} sein.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Innerhalb von {d_pl} schließt {a_pl} die Eigenschaft {b_pl} aus.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Wer {d_sg_art} und {a_sg_art} ist, kann niemals {b_sg_art} sein.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular_art'},\n",
    "            {'tpl': 'Die Kategorien {a_pl} und {b_pl} überschneiden sich bei {d_pl} nicht.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es gibt keinerlei {d_pl}, die {a_pl} und gleichzeitig {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Niemals ist ein {d_sg} sowohl {a_sg} als auch {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Falsch ist die Annahme, ein {d_sg} könne {a_sg} und {b_sg} zugleich sein.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Kein {d_sg} vereint die Merkmale von {a_sg} und {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'In der Klasse {d_pl} gibt es keine Kombination von {a_pl} und {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'}\n",
    "        ],\n",
    "        'some_not': [\n",
    "            {'tpl': 'Nicht jedes {d_sg}, das {a_sg_art} ist, ist {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Es gibt mindestens ein {d_sg}, das {a_sg_art} ist, aber nicht {b_sg_art}.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'Einige {d_pl}, die {a_pl} sind, sind nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Mindestens einige {d_pl} sind {a_pl}, jedoch nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es existiert ein {d_sg}, das {a_sg} ist, aber nicht {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Nicht alle {d_pl}, die {a_pl} sind, fallen unter {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es finden sich {d_pl}, welche {a_pl}, aber keine {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Zumindest ein {d_sg} besitzt {a_sg}, aber nicht {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Manche {d_pl} mit dem Merkmal {a_pl} sind von {b_pl} ausgeschlossen.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Es ist nicht so, dass jedes {d_sg} in {a_sg_art} auch {b_sg_art} ist.', 'a_type': 'singular_art', 'b_type': 'singular_art', 'd_type': 'singular'},\n",
    "            {'tpl': 'In {d_pl} gibt es Vertreter von {a_pl}, die nicht {b_pl} sind.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Nicht jedes Exemplar von {d_pl}, das {a_pl} ist, ist auch {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Bestimmte {d_sg} sind zwar {a_sg}, jedoch nicht {b_sg}.', 'a_type': 'singular', 'b_type': 'singular', 'd_type': 'singular'},\n",
    "            {'tpl': 'Es gibt {d_pl}, die {a_pl} sind und dennoch nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'},\n",
    "            {'tpl': 'Ein gewisser Teil der {d_pl} ist {a_pl}, aber nicht {b_pl}.', 'a_type': 'plural', 'b_type': 'plural', 'd_type': 'plural'}\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b32e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular_and_plural(term):\n",
    "    \"\"\"Return (singular, plural) using English inflect heuristics.\n",
    "    If inflect cannot determine, fall back to the term itself for both.\n",
    "    \"\"\"\n",
    "    term = term.strip()\n",
    "    # Try English singular detection\n",
    "    try:\n",
    "        sg_attempt = p.singular_noun(term)\n",
    "    except Exception:\n",
    "        sg_attempt = False\n",
    "    if sg_attempt is not False and sg_attempt is not None:\n",
    "        sg = sg_attempt\n",
    "        pl = term\n",
    "    else:\n",
    "        sg = term\n",
    "        try:\n",
    "            pl = p.plural_noun(term) or term\n",
    "        except Exception:\n",
    "            pl = term\n",
    "    return sg, pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f6bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_german(term):\n",
    "    \"\"\"Return a simple indefinite article in German for singular forms.\n",
    "    This is heuristic: returns 'eine' if term ends with 'e' (common feminine clue), else 'ein'.\n",
    "    \"\"\"\n",
    "    term = term.strip()\n",
    "    if term.endswith('e'):\n",
    "        return 'eine ' + term\n",
    "    return 'ein ' + term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0294a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence_for_type_and_terms(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    # reuse same English parsing logic (input is English)\n",
    "    match = re.match(r'All (.*) that are (.*) are (.*).', sentence)\n",
    "    if match: return 'all', match.group(1), match.group(2), match.group(3)\n",
    "    match = re.match(r'Some (.*) that are (.*) are not (.*).', sentence)\n",
    "    if match: return 'some_not', match.group(1), match.group(2), match.group(3)\n",
    "    match = re.match(r'Some (.*) that are (.*) are (.*).', sentence)\n",
    "    if match: return 'some', match.group(1), match.group(2), match.group(3)\n",
    "    match = re.match(r'No (.*) that are (.*) are (.*).', sentence)\n",
    "    if match: return 'no', match.group(1), match.group(2), match.group(3)\n",
    "    match = re.match(r'All (.*) are (.*).', sentence)\n",
    "    if match: return 'all', None, match.group(1), match.group(2)\n",
    "    match = re.match(r'Some (.*) are not (.*).', sentence)\n",
    "    if match: return 'some_not', None, match.group(1), match.group(2)\n",
    "    match = re.match(r'Some (.*) are (.*).', sentence)\n",
    "    if match: return 'some', None, match.group(1), match.group(2)\n",
    "    match = re.match(r'No (.*) are (.*).', sentence)\n",
    "    if match: return 'no', None, match.group(1), match.group(2)\n",
    "    raise ValueError(f'Could not parse basic syllogism type from sentence: {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf65df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_dict(term_original_subject, term_original_predicate, term_original_fourth, synonym_dict=None):\n",
    "    sub_map = {}\n",
    "    sg_a, pl_a = get_singular_and_plural(term_original_subject)\n",
    "    sub_map['a_sg'] = sg_a\n",
    "    sub_map['a_pl'] = pl_a\n",
    "    sub_map['a_sg_art'] = get_article_german(sg_a)\n",
    "    sg_b, pl_b = get_singular_and_plural(term_original_predicate)\n",
    "    sub_map['b_sg'] = sg_b\n",
    "    sub_map['b_pl'] = pl_b\n",
    "    sub_map['b_sg_art'] = get_article_german(sg_b)\n",
    "    if term_original_fourth:\n",
    "        sg_d, pl_d = get_singular_and_plural(term_original_fourth)\n",
    "        sub_map['d_sg'] = sg_d\n",
    "        sub_map['d_pl'] = pl_d\n",
    "        sub_map['d_sg_art'] = get_article_german(sg_d)\n",
    "    return sub_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de0d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_lowercase_first(s, sub_map):\n",
    "    for val in sub_map.values():\n",
    "        if isinstance(val, str) and s.startswith(val):\n",
    "            return s\n",
    "    return s[:1].lower() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26e7be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_syllogism_to_complex(syllogism_data, complex_patterns_data, complex_patterns_data_with_fourth_var):\n",
    "    simple_syllogism = syllogism_data['syllogism']\n",
    "    premises_simple, conclusion_simple = split_syllogism_into_sentences(simple_syllogism)\n",
    "    complex_premises = []\n",
    "    for premise in premises_simple:\n",
    "        p_type, p_fourth, p_subject, p_predicate = parse_sentence_for_type_and_terms(premise)\n",
    "        sub_map = create_sub_dict(p_subject, p_predicate, p_fourth)\n",
    "        if p_fourth:\n",
    "            p_template = random.choice(complex_patterns_data_with_fourth_var['premises'][p_type])\n",
    "        else:\n",
    "            p_template = random.choice(complex_patterns_data['premises'][p_type])\n",
    "        p_complex = p_template['tpl'].format(**sub_map)\n",
    "        p_complex = p_complex[0].upper() + p_complex[1:]\n",
    "        complex_premises.append(p_complex)\n",
    "    c_type, c_fourth, c_subject, c_predicate = parse_sentence_for_type_and_terms(conclusion_simple)\n",
    "    c_sub_map = create_sub_dict(c_subject, c_predicate, c_fourth)\n",
    "    if c_fourth:\n",
    "        c_premise_template = random.choice(complex_patterns_data_with_fourth_var['premises'][c_type])\n",
    "    else:\n",
    "        c_premise_template = random.choice(complex_patterns_data['premises'][c_type])\n",
    "    c_premise_complex = c_premise_template['tpl'].format(**c_sub_map)\n",
    "    c_premise_complex = safe_lowercase_first(c_premise_complex, c_sub_map)\n",
    "    c_wrapper_template = random.choice(complex_patterns_data['conclusions'])\n",
    "    c_complex = c_wrapper_template.format(conclusion=c_premise_complex)\n",
    "    c_complex = c_complex[:-1] if c_complex.endswith('.') else c_complex\n",
    "    c_complex = c_complex[0].upper() + c_complex[1:]\n",
    "    final_complex_syllogism = ' '.join(complex_premises) + ' ' + c_complex\n",
    "    new_data = syllogism_data.copy()\n",
    "    new_data['syllogism'] = final_complex_syllogism\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e33612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_syllogism_into_sentences(syllogism):\n",
    "    sentences = [s.strip() for s in syllogism.split('.') if s.strip()]\n",
    "    if len(sentences) < 2:\n",
    "        raise ValueError(f'Syllogism must contain at least one premise and one conclusion: {syllogism}')\n",
    "    sentences = [s + '.' for s in sentences]\n",
    "    conclusion = sentences.pop()\n",
    "    premises = sentences\n",
    "    return premises, conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87021441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(input_data, complex_patterns_data, complex_patterns_data_with_fourth_var):\n",
    "    complex_dataset = []\n",
    "    for item in input_data:\n",
    "        try:\n",
    "            complex_item = convert_syllogism_to_complex(item, complex_patterns_data, complex_patterns_data_with_fourth_var)\n",
    "            complex_dataset.append(complex_item)\n",
    "        except ValueError as e:\n",
    "            print(f' Überspringe Eintrag {item.get(id, 'N/A')} wegen Parsing-Fehler: {e}')\n",
    "            continue\n",
    "    return complex_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6769ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Überspringe Eintrag N/A wegen Parsing-Fehler: Could not parse basic syllogism type from sentence: Therefore some dogs are living things.\n",
      "[\n",
      "    {\n",
      "        \"id\": \"ex-2\",\n",
      "        \"syllogism\": \"Keine fish sind mammals. In manchen Fällen ist ein mammal eine whale. Aus diesen Gründen nicht jedes whale ist ein fish.\",\n",
      "        \"validity\": true,\n",
      "        \"plausibility\": true\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Example English input data (same style as original)\n",
    "sample_data = [\n",
    "    {\n",
    "        'id': 'ex-1',\n",
    "        'syllogism': 'All dogs are animals. All animals are living things. Therefore some dogs are living things.',\n",
    "        'validity': True,\n",
    "        'plausibility': True\n",
    "    },\n",
    "    {\n",
    "        'id': 'ex-2',\n",
    "        'syllogism': 'No fish are mammals. Some mammals are whales. Some whales are not fish.',\n",
    "        'validity': True,\n",
    "        'plausibility': True\n",
    "    }\n",
    "]\n",
    "# Run conversion using German templates\n",
    "complex_syllogism_data = process_dataset(sample_data, GERMAN_COMPLEX_PATTERNS, GERMAN_COMPLEX_PATTERNS_WITH_FOURTH_VAR)\n",
    "print(json.dumps(complex_syllogism_data, indent=4, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}